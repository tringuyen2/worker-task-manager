{
  "task_id": "demo_face_extractor",
  "name": "Demo Face Feature Extractor Task",
  "description": "Demo task for extracting face feature vectors and embeddings from detected faces",
  "version": "1.0.0",
  "author": "Demo System",
  "category": "computer_vision",
  "entry_point": "task.Task",
  "requirements": [
    "opencv-python>=4.8.0",
    "numpy>=1.24.0",
    "scikit-learn>=1.3.0"
  ],
  "tags": ["demo", "computer_vision", "face_analysis", "feature_extraction", "embeddings"],
  "queue": "face_extractor",
  "priority": 6,
  "timeout": 30,
  "max_retries": 2,
  "input_schema": {
    "input_id": "face_extractor_input_003",
    "type": "object",
    "description": "Input for face feature extraction task",
    "input_mapping": {
      "source_task": "demo_face_detection",
      "source_output_id": "face_detection_output_001",
      "mapped_fields": {
        "faces": "output_001_faces_array",
        "image_path": "input_001_image_path"
      }
    },
    "properties": {
      "faces": {
        "type": "array",
        "description": "Array of detected faces from face detection output",
        "field_id": "input_003_faces_array",
        "source_field_id": "output_001_faces_array",
        "items": {
          "type": "object",
          "properties": {
            "face_id": {
              "type": "integer",
              "field_id": "input_003_face_id",
              "source_field_id": "output_001_face_id"
            },
            "bbox": {
              "type": "array",
              "items": {"type": "integer"},
              "minItems": 4,
              "maxItems": 4,
              "field_id": "input_003_bbox",
              "source_field_id": "output_001_bbox"
            },
            "confidence": {
              "type": "number",
              "field_id": "input_003_confidence",
              "source_field_id": "output_001_confidence"
            }
          },
          "required": ["face_id", "bbox"]
        }
      },
      "image_path": {
        "type": "string",
        "description": "Path to the original image file",
        "field_id": "input_003_image_path",
        "source_field_id": "input_001_image_path"
      },
      "extraction_options": {
        "type": "object",
        "description": "Options for feature extraction",
        "field_id": "input_003_extraction_options",
        "properties": {
          "feature_dimension": {
            "type": "integer",
            "description": "Desired dimension of feature vector",
            "default": 512,
            "enum": [128, 256, 512, 1024]
          },
          "normalize_features": {
            "type": "boolean",
            "description": "Whether to L2 normalize feature vectors",
            "default": true
          },
          "extract_keypoints": {
            "type": "boolean",
            "description": "Whether to extract facial keypoints",
            "default": false
          }
        }
      }
    },
    "required": ["faces"]
  },
  "output_schema": {
    "output_id": "face_extractor_output_003",
    "type": "object",
    "description": "Face feature extraction results",
    "properties": {
      "faces": {
        "type": "array",
        "description": "Faces with extracted features",
        "field_id": "output_003_faces_with_features",
        "items": {
          "type": "object",
          "properties": {
            "face_id": {
              "type": "integer",
              "field_id": "output_003_face_id"
            },
            "bbox": {
              "type": "array",
              "items": {"type": "integer"},
              "field_id": "output_003_bbox"
            },
            "features": {
              "type": "object",
              "description": "Extracted face features",
              "field_id": "output_003_features",
              "properties": {
                "feature_vector": {
                  "type": "array",
                  "description": "Numerical feature vector representing the face",
                  "items": {"type": "number"},
                  "field_id": "output_003_feature_vector"
                },
                "feature_dimension": {
                  "type": "integer",
                  "description": "Dimension of the feature vector",
                  "field_id": "output_003_feature_dimension"
                },
                "is_normalized": {
                  "type": "boolean",
                  "description": "Whether features are L2 normalized",
                  "field_id": "output_003_is_normalized"
                },
                "keypoints": {
                  "type": "array",
                  "description": "Facial keypoints if extracted",
                  "field_id": "output_003_keypoints",
                  "items": {
                    "type": "object",
                    "properties": {
                      "point_id": {"type": "integer"},
                      "x": {"type": "number"},
                      "y": {"type": "number"},
                      "confidence": {"type": "number"}
                    }
                  }
                },
                "extraction_confidence": {
                  "type": "number",
                  "description": "Confidence score of feature extraction",
                  "minimum": 0.0,
                  "maximum": 1.0,
                  "field_id": "output_003_extraction_confidence"
                }
              },
              "required": ["feature_vector", "feature_dimension"]
            }
          },
          "required": ["face_id", "bbox", "features"]
        }
      },
      "processing_summary": {
        "type": "object",
        "description": "Summary of feature extraction",
        "field_id": "output_003_processing_summary",
        "properties": {
          "total_faces_processed": {"type": "integer"},
          "successful_extractions": {"type": "integer"},
          "failed_extractions": {"type": "integer"},
          "average_feature_dimension": {"type": "number"},
          "processing_time": {"type": "number"}
        }
      }
    },
    "required": ["faces", "processing_summary"],
    "output_mapping": {
      "primary_output": "output_003_faces_with_features",
      "feature_outputs": ["output_003_feature_vector", "output_003_feature_dimension", "output_003_keypoints"],
      "metadata_outputs": ["output_003_processing_summary", "output_003_extraction_confidence"]
    }
  }
}